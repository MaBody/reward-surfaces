{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47efdc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/git/sem5/reward-surfaces-fork\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import contextlib\n",
    "import torch\n",
    "from wrapper import utils as p_utils\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cwd = Path.cwd().parent\n",
    "print(cwd)\n",
    "# library = root.parent / \"reward-surfaces-fork\"\n",
    "scripts = cwd / \"scripts\"\n",
    "runs = cwd / \"runs\"\n",
    "\n",
    "run_suffix = \"_test\"\n",
    "env_name = \"CartPole-v1\"\n",
    "agent_name = \"SB3_ON\"\n",
    "run_id = \"cartpole\" + run_suffix\n",
    "\n",
    "num_cores = str(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "False\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/agent/ppo/CartPole-v1_3\n",
      "saved checkpoint 0010000\n",
      "Eval num_timesteps=10000, episode_reward=59.20 +/- 49.02\n",
      "Episode length: 59.20 +/- 49.02\n",
      "New best mean reward!\n",
      "saved checkpoint 0020000\n",
      "Eval num_timesteps=20000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "New best mean reward!\n",
      "saved checkpoint 0030000\n",
      "Eval num_timesteps=30000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "New best mean reward!\n",
      "saved checkpoint 0040000\n",
      "Eval num_timesteps=40000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "New best mean reward!\n",
      "saved checkpoint 0050000\n",
      "Eval num_timesteps=50000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "New best mean reward!\n"
     ]
    }
   ],
   "source": [
    "# Train RL agent\n",
    "script_name = \"train_agent\"\n",
    "args = {\n",
    "    \"save_dir\": runs / run_id / \"agent\",\n",
    "    \"agent_name\": agent_name,\n",
    "    \"env\": env_name,\n",
    "    \"device\": device,\n",
    "    \"hyperparameters\": '{\"ALGO\": \"PPO\", \"n_timesteps\":50000}',\n",
    "}\n",
    "kwargs = {\n",
    "    \"--save_freq\": str(10000),\n",
    "}\n",
    "p_utils.execute(name=script_name, args=args, kwargs=kwargs, cwd=cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ef6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2')Default hyperparameters for environment (ones being tuned will be overridden):,\n",
      "             \n",
      "('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             OrderedDict(('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001')[,\n",
      "             ('n_envs', 8),\n",
      "             ('batch_size', 256)('n_epochs', 20),\n",
      "             ,\n",
      "             ('clip_range', 'lin_0.2')('n_steps', 32),\n",
      "             ,\n",
      "             ('n_timesteps', 50000)('ent_coef', 0.0),\n",
      "             ,\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('policy', 'MlpPolicy')])('gamma', 0.98),\n",
      "             \n",
      "('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')]Using 8 environments)\n",
      "\n",
      "Using 8 environments\n",
      "cpu\n",
      "cpucpu\n",
      "\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "cpu\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_2\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_2\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_2\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_2\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_2\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_2\n",
      "Number of episodes: 100\n",
      "dumping results\n",
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [01:13<03:53, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [01:14<02:16,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n",
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:17<01:16,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:19<01:01,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_3\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_3\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_4\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_5\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_6\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_7\n",
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [02:13<03:53, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [02:16<02:44, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [02:17<01:52, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_8\n",
      "Number of episodes: 100\n",
      "dumping results\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [02:21<01:23,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_9\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_10\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Number of episodes: 100\n",
      "dumping results\n",
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [02:28<00:44,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_11\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_12\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_13\n",
      "Number of episodes: 1628\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [03:14<02:02, 17.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_14\n",
      "Number of episodes: 100\n",
      "dumping results\n",
      "Number of episodes: 100\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [03:22<00:51, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [03:26<00:33,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_15\n",
      "Number of episodes: 100\n",
      "dumping results\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [03:28<00:20,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_17\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_18\n",
      "Number of episodes: 134\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [03:38<00:15,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_19\n",
      "Number of episodes: 5238\n",
      "dumping results\n",
      "Number of episodes: 5247\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [04:19<00:17, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 100\n",
      "dumping results\n",
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 256),\n",
      "             ('clip_range', 'lin_0.2'),\n",
      "             ('ent_coef', 0.0),\n",
      "             ('gae_lambda', 0.8),\n",
      "             ('gamma', 0.98),\n",
      "             ('learning_rate', 'lin_0.001'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_epochs', 20),\n",
      "             ('n_steps', 32),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "cpu\n",
      "Number of episodes: 100\n",
      "dumping results\n",
      "Log path: /home/mattis/git/sem5/reward-surfaces-fork/runs/cartpole_test/surface/ppo/CartPole-v1_20\n",
      "Number of episodes: 4361\n",
      "dumping results\n",
      "Number of episodes: 1777\n",
      "dumping results\n",
      "Number of episodes: 121\n",
      "dumping results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [04:52<00:12, 12.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Define plane jobs\n",
    "script_name = \"generate_plane_jobs\"\n",
    "args = {\n",
    "    \"agent_dir\": runs / run_id / \"agent\" / \"best\",\n",
    "    \"out_dir\": runs / run_id / \"surface\",\n",
    "}\n",
    "kwargs = {\n",
    "    \"--grid-size\": str(5),  # str(31)\n",
    "    \"--magnitude\": str(1.0),\n",
    "    \"--num-steps\": str(50000),  # str(200000)\n",
    "    \"--device\": device,\n",
    "}\n",
    "shutil.rmtree(runs / run_id / \"surface\", ignore_errors=True)\n",
    "p_utils.execute(name=script_name, args=args, kwargs=kwargs, cwd=cwd)\n",
    "\n",
    "# Evaluate plane directions\n",
    "script_name = \"run_jobs_multiproc\"\n",
    "args = {\n",
    "    \"job_dir\": runs / run_id / \"surface\" / \"jobs.sh\",\n",
    "}\n",
    "kwargs = {\"--num-cpus\": num_cores}\n",
    "p_utils.execute(name=script_name, args=args, kwargs=kwargs, cwd=cwd)\n",
    "\n",
    "# Copy surface results to csv\n",
    "script_name = \"job_results_to_csv\"\n",
    "args = {\n",
    "    \"out_dir\": runs / run_id / \"surface\",\n",
    "}\n",
    "kwargs = {}\n",
    "p_utils.execute(name=script_name, args=args, kwargs=kwargs, cwd=cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a3800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattis/.local/share/virtualenvs/reward-surfaces-fork-0Jk62FMS/lib/python3.12/site-packages/stable_baselines3/__init__.py\n",
      "3.10.3\n"
     ]
    }
   ],
   "source": [
    "# Plot reward surface\n",
    "script_name = \"plot_plane\"\n",
    "args = {\n",
    "    \"in_dir\": runs / run_id / \"surface\" / \"results.csv\",\n",
    "}\n",
    "kwargs = {\n",
    "    \"--outname\": runs / run_id / run_id,\n",
    "    \"--env_name\": \"Cartpole\",  # \"CartPole-v1\",\n",
    "    # \"--key\": \"episode_rewards\"\n",
    "    # \"--type\": \"mesh\", # [\"all\", \"mesh\", \"vtp\", \"heat\", \"contour\",  \"contourf\"]\n",
    "}\n",
    "p_utils.execute(name=script_name, args=args, kwargs=kwargs, cwd=cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783b8018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    -1.0\n",
      "13   -1.0\n",
      "17   -1.0\n",
      "4    -1.0\n",
      "10   -1.0\n",
      "22   -0.5\n",
      "24   -0.5\n",
      "12   -0.5\n",
      "7    -0.5\n",
      "18   -0.5\n",
      "14    0.0\n",
      "6     0.0\n",
      "2     0.0\n",
      "5     0.0\n",
      "11    0.0\n",
      "15    0.5\n",
      "16    0.5\n",
      "0     0.5\n",
      "21    0.5\n",
      "19    0.5\n",
      "9     1.0\n",
      "20    1.0\n",
      "8     1.0\n",
      "23    1.0\n",
      "1     1.0\n",
      "Name: dim0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "surface",
         "x": {
          "bdata": "AAAAAAAA8L8AAAAAAADwvwAAAAAAAPC/AAAAAAAA8L8AAAAAAADwvwAAAAAAAOC/AAAAAAAA4L8AAAAAAADgvwAAAAAAAOC/AAAAAAAA4L8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4D8AAAAAAADgPwAAAAAAAOA/AAAAAAAA4D8AAAAAAADgPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8=",
          "dtype": "f8",
          "shape": "5, 5"
         },
         "y": {
          "bdata": "AAAAAAAA8L8AAAAAAADgvwAAAAAAAAAAAAAAAAAA4D8AAAAAAADwPwAAAAAAAPC/AAAAAAAA4L8AAAAAAAAAAAAAAAAAAOA/AAAAAAAA8D8AAAAAAADwvwAAAAAAAOC/AAAAAAAAAAAAAAAAAADgPwAAAAAAAPA/AAAAAAAA8L8AAAAAAADgvwAAAAAAAAAAAAAAAAAA4D8AAAAAAADwPwAAAAAAAPC/AAAAAAAA4L8AAAAAAAAAAAAAAAAAAOA/AAAAAAAA8D8=",
          "dtype": "f8",
          "shape": "5, 5"
         },
         "z": {
          "bdata": "AAAAAAAwf0AAAAAAADB/QAAAAAAAMH9AAAAAAAAwf0AAAAAAADB/QAAAAAAAMH9AAAAAAAAwf0AAAAAAADB/QAAAAAAAMH9AAAAAAAAwf0AAAAAAADB/QAAAAAAAMH9AAAAAAAAwf0AAAAAAADB/QAAAAAAAMH9AaLbS9/q3PUAT6YHK2VV3QAAAAAAAMH9AAAAAAAAwf0AAAAAAADB/QEWCblmpDyFA6Gf7nI4XIUD/5GvCkO4kQNxmlqxyJDtAOwRuLIPieUA=",
          "dtype": "f8",
          "shape": "5, 5"
         }
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from reward_surfaces import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "\n",
    "# plotting.plot_plane()\n",
    "data = pd.read_csv(runs / run_id / \"surface\" / \"results.csv\")\n",
    "data = data.sort_values([\"dim0\", \"dim1\"])\n",
    "# data\n",
    "x, y, z = data[\"dim0\"], data[\"dim1\"], data[\"episode_rewards\"]\n",
    "n = np.floor(np.sqrt(len(x))).astype(int)\n",
    "print(x.sort_values())\n",
    "X = np.reshape(x[: n**2], (n, n))\n",
    "Y = np.reshape(y[: n**2], (n, n))\n",
    "Z = np.reshape(z[: n**2], (n, n))\n",
    "# print(X.shape)\n",
    "# print(np.sin(np.meshgrid(x, y)).shape)\n",
    "# X = pickle.load(open(\"/home/mattis/git/sem5/reward_landscapes/test_X.pkl\", \"rb\"))\n",
    "# Y = pickle.load(open(\"/home/mattis/git/sem5/reward_landscapes/test_Y.pkl\", \"rb\"))\n",
    "# Z = pickle.load(open(\"/home/mattis/git/sem5/reward_landscapes/test_Z.pkl\", \"rb\"))\n",
    "# print(Z)\n",
    "fig = go.Figure(data=[go.Surface(x=X, y=Y, z=Z)])\n",
    "fig.show()\n",
    "# fig.show(figsize=(4,4))\n",
    "# print(Z)\n",
    "# fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "# ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reward-surfaces-fork-0Jk62FMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
